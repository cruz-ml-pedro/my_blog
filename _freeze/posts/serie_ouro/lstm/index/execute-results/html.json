{
  "hash": "601d918124baf73b8fa00bc1052a7160",
  "result": {
    "markdown": "---\ntitle: \"Cotação do ouro - Parte 5 \"\nsubtitle: \"Modelo LSTM\"\nauthor: \"Pedro Lima\"\ndate: \"2023-08-05\"\ncategories: [Modelagem, Série-Temporal,R]\ntoc: true\ntoc-depth: 3\ndraft: false\n---\n\n::: {.cell}\n\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-2_163b8f8e3c601fa31d091591d4e02b46'}\n\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-3_31e6e5d7b5b25491ea81b242987e9d3a'}\n\n:::\n\n\nDesenvolvendo uma estratégia de Backtesting\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-4_bd7d2432c12eb66d3f5f3711784289b2'}\n\n```{.r .cell-code}\n# Realizar o backtesting com a função rolling_origin()\nperiods_train <- 12 * 4\nperiods_test  <- 12 * 1\nskip_span     <- 12 * 2\n\n\nrolling_origin_resamples <- rsample::rolling_origin(\n    gold_mean,\n    initial    = periods_train,\n    assess     = periods_test,\n    cumulative = FALSE,\n    skip       = skip_span\n)\nrolling_origin_resamples\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Rolling origin forecast resampling \n# A tibble: 3 × 2\n  splits          id    \n  <list>          <chr> \n1 <split [48/12]> Slice1\n2 <split [48/12]> Slice2\n3 <split [48/12]> Slice3\n```\n:::\n:::\n\n\nCriando uma função para visualizar os blocos de Backtest\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-5_bb96628f7541b7b0da1369df76ef9a0e'}\n\n```{.r .cell-code}\n# Plotting function for a single split\nplot_split <- function(split, expand_y_axis = TRUE, alpha = 1, size = 1, base_size = 14) {\n    \n    # Manipulate data\n    train_tbl <- training(split) %>%\n        add_column(key = \"training\") \n    \n    test_tbl  <- testing(split) %>%\n        add_column(key = \"testing\") \n    \n    data_manipulated <- bind_rows(train_tbl, test_tbl) %>%\n        as_tbl_time(index = index) %>%\n        mutate(key = fct_relevel(key, \"training\", \"testing\"))\n        \n    # Collect attributes\n    train_time_summary <- train_tbl %>%\n        tk_index() %>%\n        tk_get_timeseries_summary()\n    \n    test_time_summary <- test_tbl %>%\n        tk_index() %>%\n        tk_get_timeseries_summary()\n    \n    # Visualize\n    g <- data_manipulated %>%\n        ggplot(aes(x = index, y = value, color = key)) +\n        geom_line(linewidth = size, alpha = alpha) +\n        theme_tq(base_size = base_size) +\n        scale_color_tq() +\n        labs(\n            title    = glue(\"Split: {split$id}\"),\n            subtitle = glue(\"{train_time_summary$start} to {test_time_summary$end}\"),\n            y = \"\", x = \"\"\n        ) +\n        theme(legend.position = \"none\") \n    \n    if (expand_y_axis) {\n        \n        gold_ts_time_summary <- gold_mean %>% \n            tk_index() %>% \n            tk_get_timeseries_summary()\n        \n        g <- g +\n            scale_x_date(limits = c(gold_ts_time_summary$start, \n                                    gold_ts_time_summary$end))\n    }\n    \n    return(g)\n}\n```\n:::\n\n\nVerificando um dos blocos de Backtest\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-6_b543df12d101a67a53bffaa4775166da'}\n\n```{.r .cell-code}\nrolling_origin_resamples$splits[[1]] %>%\n    plot_split(expand_y_axis = TRUE) +\n    theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=1440}\n:::\n:::\n\n\nFunção para colocar os gráficos na escala de tempo do recorte dos dados\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-7_6f91a06f6d32b8c52621256b81cbe0be'}\n\n```{.r .cell-code}\n# Plotting function that scales to all splits \nplot_sampling_plan <- function(sampling_tbl, expand_y_axis = TRUE, \n                               ncol = 3, alpha = 1, size = 1, base_size = 14, \n                               title = \"Sampling Plan\") {\n    \n    # Map plot_split() to sampling_tbl\n    sampling_tbl_with_plots <- sampling_tbl %>%\n        mutate(gg_plots = map(splits, plot_split, \n                              expand_y_axis = expand_y_axis,\n                              alpha = alpha, base_size = base_size))\n    \n    # Make plots with cowplot\n    plot_list <- sampling_tbl_with_plots$gg_plots \n    \n    p_temp <- plot_list[[1]] + theme(legend.position = \"bottom\")\n    legend <- get_legend(p_temp)\n    \n    p_body  <- plot_grid(plotlist = plot_list, ncol = ncol)\n    \n    p_title <- ggdraw() + \n        draw_label(title, size = 18, fontface = \"bold\", colour = palette_light()[[1]])\n    \n    g <- plot_grid(p_title, p_body, legend, ncol = 1, rel_heights = c(0.05, 1, 0.05))\n    \n    return(g)\n    \n}\n```\n:::\n\n\nPlotando todos os blocos de teste\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-8_3479265d518394389be8a0114552e45c'}\n\n```{.r .cell-code}\nrolling_origin_resamples %>%\n    plot_sampling_plan(expand_y_axis = T, ncol = 3, alpha = 1, size = 1, base_size = 10, \n                       title = \"Backtesting Strategy: Rolling Origin Sampling Plan\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-8-1.png){width=1440}\n:::\n:::\n\n\nPlotando os gráficos em uma escala mais apropriada \"zoom\"\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-9_4e94f9fd3beafe51b3612ab40e9e1158'}\n\n```{.r .cell-code}\nrolling_origin_resamples %>%\n    plot_sampling_plan(expand_y_axis = F, ncol = 3, alpha = 1, size = 1, base_size = 10, \n                       title = \"Backtesting Strategy: Zoomed In\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=1440}\n:::\n:::\n\n\n## Modelagem The Keras Stateful LSTM Model\n\n## Single LSTM\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-10_a524c37155b2ed271f613cfdc85c60da'}\n\n```{.r .cell-code}\nsplit    <- rolling_origin_resamples$splits[[1]]\nsplit_id <- rolling_origin_resamples$id[[1]]\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-11_466a34dd6d49f1c6ce330e84301f810b'}\n\n```{.r .cell-code}\nplot_split(split, expand_y_axis = FALSE, size = 0.5) +\n    theme(legend.position = \"bottom\") +\n    ggtitle(glue(\"Split: {split_id}\"))\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=1440}\n:::\n:::\n\n\nCriando um index para treino e teste e combinando em um df\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-12_f3395df0901b73fe58fcb62026e4ef0b'}\n\n```{.r .cell-code}\ndf_trn <- training(split)\ndf_tst <- testing(split)\n\ndf <- bind_rows(\n    df_trn %>% add_column(key = \"training\"),\n    df_tst %>% add_column(key = \"testing\")\n) %>% \n    as_tbl_time(index = index)\n\ndf\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A time tibble: 60 × 3\n# Index:         index\n   index      value key     \n   <date>     <dbl> <chr>   \n 1 2013-01-01  162. training\n 2 2013-02-01  158. training\n 3 2013-03-01  154. training\n 4 2013-04-01  144. training\n 5 2013-05-01  137. training\n 6 2013-06-01  130. training\n 7 2013-07-01  124. training\n 8 2013-08-01  131. training\n 9 2013-09-01  130. training\n10 2013-10-01  127. training\n# ℹ 50 more rows\n```\n:::\n:::\n\n\n## Preprocessing With Recipes\n\nThe LSTM algorithm requires the input data to be centered and scaled. We can preprocess the data using the recipes package.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-13_ddfd294555f95cb996cfa5c081953658'}\n\n```{.r .cell-code}\nrec_obj <- recipe(value ~ ., df) %>%\n    step_sqrt(value) %>%\n    step_center(value) %>%\n    step_scale(value) %>%\n   # step_BoxCox(value) %>% \n    prep()\n\ndf_processed_tbl <- bake(rec_obj, df)\n\ndf_processed_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 60 × 3\n   index      key      value\n   <date>     <fct>    <dbl>\n 1 2013-01-01 training 3.40 \n 2 2013-02-01 training 3.08 \n 3 2013-03-01 training 2.80 \n 4 2013-04-01 training 1.93 \n 5 2013-05-01 training 1.37 \n 6 2013-06-01 training 0.733\n 7 2013-07-01 training 0.277\n 8 2013-08-01 training 0.823\n 9 2013-09-01 training 0.783\n10 2013-10-01 training 0.500\n# ℹ 50 more rows\n```\n:::\n:::\n\n\nA seguir, vamos capturar o histórico do centro/escala para que possamos inverter o centro e a escala após a modelagem. A transformação da raiz quadrada pode ser revertida ao elevar ao quadrado os valores invertidos do centro/escala.\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-14_4147f4225254d12c7dc87da0abeed475'}\n\n```{.r .cell-code}\n   center_history <- rec_obj$steps[[2]]$means[\"value\"]\n   scale_history  <- rec_obj$steps[[3]]$sds[\"value\"]\n\nc(\"center\" = center_history, \"scale\" = scale_history)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ncenter.value  scale.value \n  11.0197810    0.4985484 \n```\n:::\n:::\n\n\n## LSTM Plan\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-15_63955358c87479fd036cf0dc8a460a8b'}\n\n```{.r .cell-code}\n# Model inputs\nlag_setting  <- 12 # = nrow(df_tst)\nbatch_size   <- 1\ntrain_length <- 12*6\ntsteps       <- 1\nepochs       <- 50\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-16_3fa5110fee48eaf37100bd13cd8585de'}\n\n```{.r .cell-code}\n# Training Set\nlag_train_tbl <- df_processed_tbl %>%\n    mutate(value_lag = lag(value, n = lag_setting)) %>%\n    filter(!is.na(value_lag)) %>%\n    filter(key == \"training\") %>%\n    tail(train_length)\n\nx_train_vec <- lag_train_tbl$value_lag\nx_train_arr <- array(data = x_train_vec, dim = c(length(x_train_vec), 1, 1))\n\ny_train_vec <- lag_train_tbl$value\ny_train_arr <- array(data = y_train_vec, dim = c(length(y_train_vec), 1))\n\n# Testing Set\nlag_test_tbl <- df_processed_tbl %>%\n    mutate(\n        value_lag = lag(value, n = lag_setting)\n    ) %>%\n    filter(!is.na(value_lag)) %>%\n    filter(key == \"testing\")\n\nx_test_vec <- lag_test_tbl$value_lag\nx_test_arr <- array(data = x_test_vec, dim = c(length(x_test_vec), 1, 1))\n\ny_test_vec <- lag_test_tbl$value\ny_test_arr <- array(data = y_test_vec, dim = c(length(y_test_vec), 1))\n```\n:::\n\n\n### Construindo o modelo LSTM\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-17_5877cbef5ff08d7c21b4407493c95eb0'}\n\n```{.r .cell-code}\nmodel <- keras_model_sequential()\n\nmodel %>%\n    layer_lstm(units            = 50, \n               input_shape      = c(tsteps, 1), \n               batch_size       = batch_size,\n               return_sequences = TRUE, \n               stateful         = TRUE) %>% \n     layer_lstm(units            = 50, \n                return_sequences = FALSE, \n                stateful         = TRUE) %>% \n    layer_dense(units = 1)\n\nmodel %>% \n    compile(\n      loss = 'mae',\n      optimizer = 'adam',\n      ) \n  \n\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nModel: \"sequential\"\n________________________________________________________________________________\n Layer (type)                       Output Shape                    Param #     \n================================================================================\n lstm_1 (LSTM)                      (1, 1, 50)                      10400       \n lstm (LSTM)                        (1, 50)                         20200       \n dense (Dense)                      (1, 1)                          51          \n================================================================================\nTotal params: 30,651\nTrainable params: 30,651\nNon-trainable params: 0\n________________________________________________________________________________\n```\n:::\n:::\n\n\n### Fitting The LSTM Model\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-18_1c30d07fd27e760746a4db3b52493524'}\n\n```{.r .cell-code}\nfor (i in 1:epochs) {\n    model %>% fit(x          = x_train_arr, \n                  y          = y_train_arr, \n                  batch_size = batch_size,\n                  epochs     = 1, \n                  verbose    = 1, \n                  shuffle    = FALSE)\n    \n    model %>% reset_states()\n    cat(\"Epoch: \", i)\n    \n}\n```\n:::\n\n\n### Predicting Using The LSTM Model\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-19_d8b0f5ef1eb178bcc00349ab1b6c1a3b'}\n\n```{.r .cell-code}\n# Make Predictions\npred_out <- model %>% \n    predict(x_test_arr, batch_size = batch_size) %>%\n    .[,1] \n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n 1/12 [=>............................] - ETA: 9s\n12/12 [==============================] - 1s 2ms/step\n```\n:::\n\n```{.r .cell-code}\n# Retransform values\npred_tbl <- tibble(\n    index   = lag_test_tbl$index,\n    value   = (pred_out * scale_history + center_history)^2\n) \n\n# Combine actual data with predictions\ntbl_1 <- df_trn %>%\n    add_column(key = \"actual\")\n\ntbl_2 <- df_tst %>%\n    add_column(key = \"actual\")\n\ntbl_3 <- pred_tbl %>%\n    add_column(key = \"predict\")\n\n# Create time_bind_rows() to solve dplyr issue\ntime_bind_rows <- function(data_1, data_2, index) {\n    index_expr <- enquo(index)\n    bind_rows(data_1, data_2) %>%\n        as_tbl_time(index = !! index_expr)\n}\n\nret <- list(tbl_1, tbl_2, tbl_3) %>%\n    reduce(time_bind_rows, index = index) %>%\n    arrange(key, index) %>%\n    mutate(key = as_factor(key))\n\nret\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A time tibble: 72 × 3\n# Index:         index\n   index      value key   \n   <date>     <dbl> <fct> \n 1 2013-01-01  162. actual\n 2 2013-02-01  158. actual\n 3 2013-03-01  154. actual\n 4 2013-04-01  144. actual\n 5 2013-05-01  137. actual\n 6 2013-06-01  130. actual\n 7 2013-07-01  124. actual\n 8 2013-08-01  131. actual\n 9 2013-09-01  130. actual\n10 2013-10-01  127. actual\n# ℹ 62 more rows\n```\n:::\n:::\n\n\n### Assessing Performance Of The LSTM On A Single Split\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-20_40fdc7533ecd00020bc0a8aaf916e862'}\n\n```{.r .cell-code}\ncalc_rmse <- function(prediction_tbl) {\n    \n    rmse_calculation <- function(data) {\n        data %>%\n            spread(key = key, value = value) %>%\n            select(-index) %>%\n            filter(!is.na(predict)) %>%\n            rename(\n                truth    = actual,\n                estimate = predict\n            ) %>%\n            rmse(truth, estimate) %>% \n      select(.estimate)\n    }\n    \n    safe_rmse <- possibly(rmse_calculation, otherwise = NA)\n    \n    safe_rmse(prediction_tbl)\n        \n}\n```\n:::\n\n\nverificando o RMSE\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-21_ef52175b241332c6816251414cfe229e'}\n\n```{.r .cell-code}\ncalc_rmse(ret)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 1\n  .estimate\n      <dbl>\n1      3.85\n```\n:::\n:::\n\n\n### Visualizing The Single Prediction\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-22_44f409a59c66c4c964cb099e934c42ea'}\n\n```{.r .cell-code}\n# Setup single plot function\nplot_prediction <- function(data, id, alpha = 1, size = 2, base_size = 14) {\n    \n    rmse_val <- calc_rmse(data)\n    \n    g <- data %>%\n        ggplot(aes(index, value, color = key)) +\n        geom_point(alpha = alpha, size = size) + \n        theme_tq(base_size = base_size) +\n        scale_color_tq() +\n        theme(legend.position = \"none\") +\n        labs(\n            title = glue(\"{id}, RMSE: {round(rmse_val, digits = 1)}\"),\n            x = \"\", y = \"\"\n        )\n    \n    return(g)\n}\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-23_272079cd8ea7a1cbd5f21d151541cae0'}\n\n```{.r .cell-code}\nret %>% \n    plot_prediction(id = split_id, alpha = 0.65) +\n    theme(legend.position = \"bottom\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-23-1.png){width=1440}\n:::\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-24_7810411ee0012b65b8e77f0910a66007'}\n\n```{.r .cell-code}\n# trend <- fit %>% \n#    filter(index >=  \"2023-01-08\", index <= \"2023-02-06\") %>% \n#    select(trend) %>% \n#    tibble()\n# \n# \n# predito <- ret %>% \n#   filter(key==\"predict\") %>% \n#   mutate(\n#     value = value + trend\n#   )\n# \n# original <- gold_original %>% \n#   filter(index >=  \"2023-01-08\", index <= \"2023-02-06\")\n# \n# left_join(original, predito, by = \"index\") %>% \n#   ggplot(aes(x=index))+\n#   geom_line(aes(y=value.x))+\n#   geom_line(aes(y=value.y$trend), color=\"blue\")\n```\n:::\n\n\n### Backtesting The LSTM On All Samples Creating An LSTM Prediction Function\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-25_ef483ba8dd7042897808e5d2bfcd53be'}\n\n```{.r .cell-code}\npredict_keras_lstm <- function(split, epochs = 50, ...) {\n    \n    lstm_prediction <- function(split, epochs, ...) {\n        \n        # 5.1.2 Data Setup\n        df_trn <- training(split)\n        df_tst <- testing(split)\n        \n        df <- bind_rows(\n            df_trn %>% add_column(key = \"training\"),\n            df_tst %>% add_column(key = \"testing\")\n        ) %>% \n            as_tbl_time(index = index)\n        \n        # 5.1.3 Preprocessing\n        rec_obj <- recipe(value ~ ., df) %>%\n            step_sqrt(value) %>%\n            step_center(value) %>%\n            step_scale(value) %>%\n            prep()\n        \n        df_processed_tbl <- bake(rec_obj, df)\n        \n        center_history <- rec_obj$steps[[2]]$means[\"value\"]\n        scale_history  <- rec_obj$steps[[3]]$sds[\"value\"]\n        \n        # 5.1.4 LSTM Plan\n        lag_setting  <- 12 # = nrow(df_tst)\n        batch_size   <- 1\n        train_length <- 12*5\n        tsteps       <- 1\n        epochs       <- epochs\n        \n        # 5.1.5 Train/Test Setup\n        lag_train_tbl <- df_processed_tbl %>%\n            mutate(value_lag = lag(value, n = lag_setting)) %>%\n            filter(!is.na(value_lag)) %>%\n            filter(key == \"training\") %>%\n            tail(train_length)\n        \n        x_train_vec <- lag_train_tbl$value_lag\n        x_train_arr <- array(data = x_train_vec, dim = c(length(x_train_vec), 1, 1))\n        \n        y_train_vec <- lag_train_tbl$value\n        y_train_arr <- array(data = y_train_vec, dim = c(length(y_train_vec), 1))\n        \n        lag_test_tbl <- df_processed_tbl %>%\n            mutate(\n                value_lag = lag(value, n = lag_setting)\n            ) %>%\n            filter(!is.na(value_lag)) %>%\n            filter(key == \"testing\")\n        \n        x_test_vec <- lag_test_tbl$value_lag\n        x_test_arr <- array(data = x_test_vec, dim = c(length(x_test_vec), 1, 1))\n        \n        y_test_vec <- lag_test_tbl$value\n        y_test_arr <- array(data = y_test_vec, dim = c(length(y_test_vec), 1))\n                \n        # 5.1.6 LSTM Model\n        model <- keras_model_sequential()\n\n        model %>%\n            layer_lstm(units            = 50, \n                       input_shape      = c(tsteps, 1), \n                       batch_size       = batch_size,\n                       return_sequences = TRUE, \n                       stateful         = TRUE) %>% \n            layer_lstm(units            = 50, \n                       return_sequences = FALSE, \n                       stateful         = TRUE) %>% \n            layer_dense(units = 1)\n        \n        model %>% \n            compile(loss = 'mae', optimizer = 'adam')\n        \n        # 5.1.7 Fitting LSTM\n        for (i in 1:epochs) {\n            model %>% fit(x          = x_train_arr, \n                          y          = y_train_arr, \n                          batch_size = batch_size,\n                          epochs     = 1, \n                          verbose    = 1, \n                          shuffle    = FALSE)\n            \n            model %>% reset_states()\n            cat(\"Epoch: \", i)\n            \n        }\n        \n        # 5.1.8 Predict and Return Tidy Data\n        # Make Predictions\n        pred_out <- model %>% \n            predict(x_test_arr, batch_size = batch_size) %>%\n            .[,1] \n        \n        # Retransform values\n        pred_tbl <- tibble(\n            index   = lag_test_tbl$index,\n            value   = (pred_out * scale_history + center_history)^2\n        ) \n        \n        # Combine actual data with predictions\n        tbl_1 <- df_trn %>%\n            add_column(key = \"actual\")\n        \n        tbl_2 <- df_tst %>%\n            add_column(key = \"actual\")\n        \n        tbl_3 <- pred_tbl %>%\n            add_column(key = \"predict\")\n        \n        # Create time_bind_rows() to solve dplyr issue\n        time_bind_rows <- function(data_1, data_2, index) {\n            index_expr <- enquo(index)\n            bind_rows(data_1, data_2) %>%\n                as_tbl_time(index = !! index_expr)\n        }\n        \n        ret <- list(tbl_1, tbl_2, tbl_3) %>%\n            reduce(time_bind_rows, index = index) %>%\n            arrange(key, index) %>%\n            mutate(key = as_factor(key))\n\n        return(ret)\n        \n    }\n    \n    safe_lstm <- possibly(lstm_prediction, otherwise = NA)\n    \n    safe_lstm(split, epochs, ...)\n    \n}\n```\n:::\n\n\ntestando\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-26_8098234842746dac95482be632011b7e'}\n\n```{.r .cell-code}\n#predict_keras_lstm(split, epochs = 10)\n```\n:::\n\n\n### Mapping The LSTM Prediction Function Over The Samples\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-27_db299acf7eaa583bde521e6fd956a8e9'}\n\n```{.r .cell-code}\nsample_predictions_lstm_tbl <- rolling_origin_resamples %>%\n     mutate(predict = map(splits, predict_keras_lstm, epochs = 50))\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-28_7bd1805c738360ab886a1a45105719d3'}\n\n```{.r .cell-code}\nsample_predictions_lstm_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Rolling origin forecast resampling \n# A tibble: 3 × 3\n  splits          id     predict            \n  <list>          <chr>  <list>             \n1 <split [48/12]> Slice1 <tbl_time [72 × 3]>\n2 <split [48/12]> Slice2 <tbl_time [72 × 3]>\n3 <split [48/12]> Slice3 <tbl_time [72 × 3]>\n```\n:::\n:::\n\n\n### Assessing The Backtested Performance\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-29_d9ae29d432f838eb46142a3bb9d6d5cb'}\n\n```{.r .cell-code}\nsample_rmse_tbl <- sample_predictions_lstm_tbl %>%\n    mutate(rmse = map_df(predict, calc_rmse)) %>%\n    select(id, rmse) \n\nsample_rmse_tbl\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  id     rmse$.estimate\n  <chr>           <dbl>\n1 Slice1           4.04\n2 Slice2          14.7 \n3 Slice3          54.1 \n```\n:::\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-30_69da402b8706c441774ba3d9b004d018'}\n\n```{.r .cell-code}\nsample_rmse_tbl %>%\n    ggplot(aes(rmse$.estimate)) +\n    geom_histogram(aes(y = ..density..), fill = palette_light()[[1]], bins = 16) +\n    geom_density(fill = palette_light()[[1]], alpha = 0.5) +\n    theme_tq() +\n    ggtitle(\"Histogram of RMSE\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-30-1.png){width=1440}\n:::\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-31_6018b813a997625c537b03596287149e'}\n\n```{.r .cell-code}\nsample_rmse_tbl$rmse %>%\n    summarize(\n        mean_rmse = mean(.estimate),\n        sd_rmse   = sd(.estimate)\n    )\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 2\n  mean_rmse sd_rmse\n      <dbl>   <dbl>\n1      24.3    26.4\n```\n:::\n:::\n\n\nVisualizing The Backtest Results\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-32_acbbec14daef1ab31aa93a8bd83e0286'}\n\n```{.r .cell-code}\nplot_predictions <- function(sampling_tbl, predictions_col, \n                             ncol = 3, alpha = 1, size = 2, base_size = 14,\n                             title = \"Backtested Predictions\") {\n    \n    predictions_col_expr <- enquo(predictions_col)\n    \n    # Map plot_split() to sampling_tbl\n    sampling_tbl_with_plots <- sampling_tbl %>%\n        mutate(gg_plots = map2(!! predictions_col_expr, id, \n                               .f        = plot_prediction, \n                               alpha     = alpha, \n                               size      = size, \n                               base_size = base_size)) \n    \n    # Make plots with cowplot\n    plot_list <- sampling_tbl_with_plots$gg_plots \n    \n    p_temp <- plot_list[[1]] + theme(legend.position = \"bottom\")\n    legend <- get_legend(p_temp)\n    \n    p_body  <- plot_grid(plotlist = plot_list, ncol = ncol)\n    \n    \n    \n    p_title <- ggdraw() + \n        draw_label(title, size = 18, fontface = \"bold\", colour = palette_light()[[1]])\n    \n    g <- plot_grid(p_title, p_body, legend, ncol = 1, rel_heights = c(0.05, 1, 0.05))\n    \n    return(g)\n    \n}\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-33_cba8230f4e5601df0f2af2416c5804e9'}\n\n```{.r .cell-code}\nsample_predictions_lstm_tbl %>%\n    plot_predictions(predictions_col = predict, alpha = 0.5, size = 1, base_size = 10,\n                     title = \"Keras Stateful LSTM: Backtested Predictions\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-33-1.png){width=1440}\n:::\n:::\n\n\n### Predicting The Next 10 Years\n\n\n::: {.cell hash='index_cache/html/unnamed-chunk-34_f52946d343d708b05cdcc08dbee82d65'}\n\n```{.r .cell-code}\npredict_keras_lstm_future <- function(data, epochs = 300, ...) {\n    \n    lstm_prediction <- function(data, epochs, ...) {\n        \n        # 5.1.2 Data Setup (MODIFIED)\n        df <- data\n        \n        # 5.1.3 Preprocessing\n        rec_obj <- recipe(value ~ ., df) %>%\n            step_sqrt(value) %>%\n            step_center(value) %>%\n            step_scale(value) %>%\n            prep()\n        \n        df_processed_tbl <- bake(rec_obj, df)\n        \n        center_history <- rec_obj$steps[[2]]$means[\"value\"]\n        scale_history  <- rec_obj$steps[[3]]$sds[\"value\"]\n        \n        # 5.1.4 LSTM Plan\n        lag_setting  <- 12 # = nrow(df_tst)\n        batch_size   <- 1\n        train_length <- 12*3\n        tsteps       <- 1\n        epochs       <- epochs\n        \n        # 5.1.5 Train Setup (MODIFIED)\n        lag_train_tbl <- df_processed_tbl %>%\n            mutate(value_lag = lag(value, n = lag_setting)) %>%\n            filter(!is.na(value_lag)) %>%\n            tail(train_length)\n        \n        x_train_vec <- lag_train_tbl$value_lag\n        x_train_arr <- array(data = x_train_vec, dim = c(length(x_train_vec), 1, 1))\n        \n        y_train_vec <- lag_train_tbl$value\n        y_train_arr <- array(data = y_train_vec, dim = c(length(y_train_vec), 1))\n        \n        x_test_vec <- y_train_vec %>% tail(lag_setting)\n        x_test_arr <- array(data = x_test_vec, dim = c(length(x_test_vec), 1, 1))\n                \n        # 5.1.6 LSTM Model\n        model <- keras_model_sequential()\n\n        model %>%\n            layer_lstm(units            = 50, \n                       input_shape      = c(tsteps, 1), \n                       batch_size       = batch_size,\n                       return_sequences = TRUE, \n                       stateful         = TRUE) %>% \n            layer_lstm(units            = 50, \n                       return_sequences = FALSE, \n                       stateful         = TRUE) %>% \n            layer_dense(units = 1)\n        \n        model %>% \n            compile(loss = 'mae', optimizer = 'adam')\n        \n        # 5.1.7 Fitting LSTM\n        for (i in 1:epochs) {\n            model %>% fit(x          = x_train_arr, \n                          y          = y_train_arr, \n                          batch_size = batch_size,\n                          epochs     = 1, \n                          verbose    = 1, \n                          shuffle    = FALSE)\n            \n            model %>% reset_states()\n            cat(\"Epoch: \", i)\n            \n        }\n        \n        # 5.1.8 Predict and Return Tidy Data (MODIFIED)\n        # Make Predictions\n        pred_out <- model %>% \n            predict(x_test_arr, batch_size = batch_size) %>%\n            .[,1] \n        \n        # Make future index using tk_make_future_timeseries()\n        idx <- data %>%\n            tk_index() %>%\n            tk_make_future_timeseries(length_out = lag_setting)\n        \n        # Retransform values\n        pred_tbl <- tibble(\n            index   = idx,\n            value   = (pred_out * scale_history + center_history)^2\n        )\n        \n        # Combine actual data with predictions\n        tbl_1 <- df %>%\n            add_column(key = \"actual\")\n\n        tbl_3 <- pred_tbl %>%\n            add_column(key = \"predict\")\n\n        # Create time_bind_rows() to solve dplyr issue\n        time_bind_rows <- function(data_1, data_2, index) {\n            index_expr <- enquo(index)\n            bind_rows(data_1, data_2) %>%\n                as_tbl_time(index = !! index_expr)\n        }\n\n        ret <- list(tbl_1, tbl_3) %>%\n            reduce(time_bind_rows, index = index) %>%\n            arrange(key, index) %>%\n            mutate(key = as_factor(key))\n\n        return(ret)\n        \n    }\n    \n    safe_lstm <- possibly(lstm_prediction, otherwise = NA)\n    \n    safe_lstm(data, epochs, ...)\n    \n}\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-35_ccbe14689132eff0740ae7442f173f3e'}\n\n```{.r .cell-code}\nfuture_gold_ts_tbl <- predict_keras_lstm_future(gold_mean, epochs = 300)\n```\n:::\n\n::: {.cell hash='index_cache/html/unnamed-chunk-36_d6dce76a0ac170ab7a6075dc285d64b4'}\n\n```{.r .cell-code}\nfuture_gold_ts_tbl %>%\n    filter_time(\"2013\" ~ \"end\") %>%\n    plot_prediction(id = NULL, alpha = 0.4, size = 1.5) +\n    theme(legend.position = \"bottom\") +\n    ggtitle(\"Sunspots: Ten Year Forecast\", subtitle = \"Forecast Horizon: 2013 - 2023\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-36-1.png){width=1440}\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}