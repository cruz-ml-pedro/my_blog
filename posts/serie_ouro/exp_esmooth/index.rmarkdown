---
title: "Cotação do ouro - Parte 3"
subtitle: "Suavização Exponencial"
author: "Pedro Lima"
date: "2023-10-30"
categories: [Modelos Estatísticos, Série-Temporal,R]
toc: true
toc-depth: 3
draft: true
---

```{r, echo=FALSE}
knitr::opts_chunk$set(cache = TRUE, cache.lazy = FALSE, warning = FALSE,
                      message = FALSE, echo = TRUE, dpi = 180,
                      fig.width = 8, fig.height = 5)

pacman::p_load(tidyverse,tidyquant,tidymodels,timetk, modeltime,
               modeltime.resample)

# This toggles plots from plotly (interactive) to ggplot (static)
interactive <- FALSE
```

```{r, echo=FALSE}
# Obter dados da ação de ouro (código GLD)
gold_data <- tq_get("GLD")
```

```{r, echo=FALSE}
gold_mean <-
  gold_data %>% 
  group_by(mes = format(date, "%Y-%m")) %>%
  summarize(media = mean(close, na.rm = TRUE)) %>% 
   mutate(
    mes=as_date(mes, format="%Y-%m")
    )
```

```{css, echo=FALSE}
.justify {
  text-align: justify;
}
```


# Introdução
::: justify
Esta postagem será a primeira da série voltada para a construção de um modelo preditivo. Os dados utilizados, assim como a escolha de alguns dos parâmetros usados para criar os modelos subsequentes, foram adquiridos e sugeridos, na [Parte Um](https://pedroom-blog.netlify.app/posts/serie_ouro/eda/) e na [Parte Dois](https://pedroom-blog.netlify.app/posts/serie_ouro/eda2/) desta série, durante a análise exploratória dos dados.

Como primeira abordagem serão testados modelos de suavização exponencial. O pacote escolhido para realizar esta tarefa foi o `modeltime`, uma extensão do ecossistema `tidymodels`. Além disso, utilizarei o pacote complementar `modeltime.resample` para a validação cruzada e o backtesting.
:::

# Suavização Exponencial
::: justify
"A suavização exponencial foi proposta no final dos anos 1950 (Brown, 1959; Holt, 1957; Winters, 1960) e motivou alguns dos métodos de previsão mais bem-sucedidos. As previsões produzidas usando métodos de suavização exponencial são médias ponderadas das observações passadas, com os pesos diminuindo exponencialmente à medida que as observações envelhecem. Em outras palavras, quanto mais recente for a observação, maior será o peso associado a ela" (Hyndman e Athanasopoulos, 2021).  

Comumente chamados de ETS (do inglês Erros, Trend, Season), essa família de modelos foi desenvolvida originalemnte para séries sem tendência e sazonalidade. Sendo expandida posteriormente para séries com tendência, por Holt (1957), e com sazonalidade por Winters (1960). O funcionamento básico deste método se dá através de três equações de suavização, uma para o nível $\ell_t$, uma para a tendência $b_t$ e uma para o componente sazonal $s_t$, com os parâmetros de suavização correspondentes $\alpha$, $\beta^*$, $\gamma$.    

A seguir uma breve descrição da evolução do método, o que torna mais fácil o entendimento das equações e parâmetros mencionados.

## Suavização Exponencial Simples

Podendo ser entendida como um "meio termo" entre o método de Naïve, onde só a medida mais próxima teria inportância $(\hat{y}_{T+h|T} = y_T)$, e uma média simples, onde todas as medidas tem a mesma importância $(\hat{y}_{T+h|T} = \frac{1}{T} \sum_{t=1}^{T} y_t)$. A suavização exponencial simples tem os seus valores calculados usando médias ponderadas, onde os pesos diminuem exponencialmente à medida que as observações "envelhecem". Assim o valor suavizado da série é dado por: 

$$y_{T+1|T} = \alpha y_T + \alpha (1 - \alpha) y_{T-1} + \alpha (1 - \alpha)^2 y_{T-2} + \ldots,$$ 

Equação de Previsão  

$$\hat{y}_{t+h|t} = \ell_t,$$

Equação de Suavização  

$$\ell_t = \alpha y_t + (1 - \alpha) \ell_{t-1},$$ 

onde $0 \leq \alpha \leq 1$ é o parâmetro de suavização. A previsão de um passo à frente para o tempo T+1 é uma média ponderada de todas as observações na série $y_1, \ldots, y_T$. A taxa pela qual os pesos diminuem é controlada pelo parâmetro $\alpha$. E $(\ell_t)$ representa o nível (ou o valor suavizado) da série no tempo $(t)$.

## Suavização Exponencial com Tendência

O próximo passo envolve a inclusão dos casos em que há presença de tendência nos dados. Nesse cenário, as equações são atualizadas para:

Equação de previsão  

$$y_{t+h|t} = \ell_t + h b_t$$

Equação de suavização (nível)  

$$ℓ_t = αy_t + (1 - α)(ℓ_{t-1} + b_{t-1})$$

Equação da tendência  

$$b_t = \beta^* (\ell_t - \ell_{t-1}) + (1 - \beta^*) b_{t-1}$$

Onde $(\ell_t)$ denota uma estimativa do nível da série no tempo $(t)$, $(b_t)$ denota uma estimativa da tendência (inclinação) da série no tempo $(t)$, $(\alpha)$ é o parâmetro de suavização para o nível, $(0 \leq \alpha \leq 1)$, e $(\beta^*)$ é o parâmetro de suavização para a tendência, $(0 \leq \beta^* \leq 1)$. 

Assim como na suavização exponencial simples, a equação de $(\ell_t)$ aqui mostra que $(\ell_t)$ é uma média ponderada da observação $(y_t)$ e da previsão de treinamento de um passo à frente para o tempo $(t)$, aqui dada por $(\ell_{t-1} + b_{t-1})$. A equação de $(b_t)$ mostra que $(b_t)$ é uma média ponderada da tendência estimada no tempo $(t)$ com base em $(\ell_t - \ell_{t-1})$ e $(b_{t-1})$, a estimativa anterior da tendência.

A função de previsão não é mais plana, mas apresenta tendência. A $(h)$-previsão à frente é igual ao último nível estimado mais $(h)$ vezes o último estimado valor da tendência. Portanto, as previsões são uma função linear de $(h)$.

## Suavização Exponencial com Sazonalidade

A versão mais completa desta família de modelos engloba uma equação para capturar a componente sazonal. Existem duas variações deste método que diferem na natureza do componente sazonal. O método aditivo é preferível quando as variações sazonais são aproximadamente constantes ao longo da série, enquanto o método multiplicativo é preferível quando as variações sazonais estão mudando proporcionalmente ao nível da série.

A versão aditiva é descrita da seguinte forma:

\begin{align*}
\hat{y}_{t+h|t} &= \ell_t + h b_t + s_{t-m(k+1)} \\
\ell_t &= \alpha (y_t - s_t - m) + (1 - \alpha)(\ell_{t-1} + b_{t-1}) \\
b_t &= \beta^* (\ell_t - \ell_{t-1}) + (1 - \beta^*) b_{t-1} \\
s_t &= \gamma (y_t - \ell_{t-1} - b_{t-1}) + (1 - \gamma) s_{t-m} \\
\end{align*}

Onde $(k)$ é a parte inteira de $(\frac{{h - 1}}{m})$, o que garante que as estimativas dos índices sazonais usados para previsões provenham do último ano da amostra. A equação de nível mostra uma média ponderada entre a observação ajustada sazonalmente $(y_t - s_t - m)$ e a previsão não sazonal $(\ell_{t-1} + b_{t-1})$ para o tempo $(t)$. A equação de tendência é idêntica ao método linear de Holt. A equação sazonal mostra uma média ponderada entre o índice sazonal atual $(y_t - \ell_{t-1} - b_{t-1})$ e o índice sazonal do mesmo período do ano anterior (ou seja, $(m)$ períodos atrás).

A equação para o componente sazonal é frequentemente expressa como:

$$
s_t = \gamma^* (y_t - \ell_t) + (1 - \gamma^*) s_{t-m}
$$

Se substituirmos $(\ell_t)$ a partir da equação de suavização para o nível do componente acima, obtemos:

$$
s_t = \gamma^* (1 - \alpha) (y_t - \ell_{t-1} - b_{t-1}) + [1 - \gamma^* (1 - \alpha)] s_{t-m}
$$

o que é idêntico à equação de suavização para o componente sazonal que especificamos aqui, com $(\gamma = \gamma^* (1 - \alpha))$. A restrição usual para o parâmetro é $(0 \leq \gamma^* \leq 1)$, o que se traduz em $(0 \leq \gamma \leq 1 - \alpha)$.


Lembrando que esta é apenas uma simplificação da aplicação do método aditivo de Holt-Winters. Para uma discussão mais detalhada, você pode consultar o [capítulo 8](https://otexts.com/fpp3/expsmooth.html) do livro "Forecasting: Principles and Practice" e as referências ali mencionadas.
:::

# Engines
::: jistify
O pacote utilizado para criação dos modelos disponibiliza diferentes engines:

-  ets: "Função padrão para os modelos ETS. Esta funcionalidade é proveniente do pacote `forecast` e permite a aplicação da metodologia de forma totalmente automática. Além do modo automático, permite ao usuário escolher os parâmetros $\alpha$, $\beta^*$, $\gamma$, bem como os tipos de componentes de erro, tendência e sazonalidade, sejam eles aditivos, multiplicativos ou do tipo aditivo 'damped', etc.

-  smooth_es: A função funciona como a anterior e retorna a previsão, os valores ajustados, os erros e a matriz de estados. Essa engine é ajustada através de uma função 'adam' (Adaptive Moment Estimation), algoritmo amplamente utilizado para otimizar funções objetivo. Ele é uma variação do gradiente descendente estocástico (SGD) que adapta automaticamente as taxas de aprendizado para cada parâmetro do modelo durante o treinamento. Isso ajuda a melhorar a convergência e a eficiência do treinamento, tornando-o especialmente eficaz em problemas complexos.

-  CROSTON: Um caso especial de Suavização Exponencial para demanda intermitente.

-  Theta: Um caso especial de Suavização Exponencial com 'drift' que teve um bom desempenho na Competição M3.

-  stlm_ets: As previsões de objetos STL são obtidas aplicando um método de previsão não sazonal aos dados ajustados sazonalmente e, em seguida, recompondo-os usando o último ano do componente sazonal. Essa abordagem permite o uso de diferentes periodicidades na construção do modelo.

As 'engines' que serão utilizadas serão a ets e stlm_ets.
:::

# Plano de Validação Cruzada
::: juntify
Antes de iniciarmos a construção do modelo vamos estabelecer um plano de validação cruzada.

A validação cruzada é uma técnica fundamental em aprendizado de máquina e estatística. Ela ajuda a avaliar o desempenho de modelos ao dividir os dados em conjuntos de treinamento e teste múltiplos, mitigando o viés de seleção do conjunto de teste e fornecendo uma estimativa mais confiável do desempenho do modelo em dados não vistos. Isso é essencial para escolher e ajustar modelos de maneira adequada e geralmente envolve k-folds, onde o conjunto de dados é dividido em k partes iguais, alternando entre treinamento e teste para cada iteração.

Para a criação dos folders, será utilizada a função `time_series_cv` do pacote `timetk`. Os dados originais serão divididos em oito novos conjuntos, nos quais seis anos serão destinados para "treino" e um ano para teste, com um intervalo de meio ano entre os folders. A criação dos modelos e a primeira avaliação serão realizadas no folder número 1, que contém os dados mais recentes. Para avaliar a estabilidade do modelo em épocas passadas, os demais folders serão utilizados.


```{r}
cv <- 
  gold_mean %>% 
 timetk::time_series_cv(
    assess      = 12 * 1,
    initial     = 12 * 6,
    skip        = 12 * 0.5,
    slice_limit = 8,
    culmulatime = TRUE
  )

```


## Visualizando o plano de Validação Cruzada


```{r}
cv %>% 
  tk_time_series_cv_plan() %>% 
  plot_time_series_cv_plan(mes,media, .facet_ncol = 2, .interactive = FALSE)
```

:::

# Criando os Modelos
::: justify
Com base nos resultados obtidos durante a análise exploratória, os primeiros modelos foram criados da seguinte forma: foram desenvolvidos modelos com sazonalidade de 12 meses, modelos com sazonalidade de 16 meses $\texttt{(ETS)}$ e modelos com múltiplas sazonalidades de 12 meses e 16 meses $\texttt{(STLM-ETS)}$. Os modelos com sazonalidade de 12 meses $\texttt{(ETS)}$ apresentaram um desempenho inferior e, aparentemente, não conseguiram capturar adequadamente o comportamento dos dados. Portanto, eles não serão utilizados no restante deste estudo.

Os modelos ETS que incorporaram a componente sazonal multiplicativa, identificada durante a Análise Exploratória de Dados (EDA), apresentaram um desempenho inferior em comparação com os modelos aditivos. Notavelmente, a configuração $\texttt{ETS(M,A,A)}$ foi a que obteve o melhor desempenho.

Os modelos selecionados para comparação e análise incluem o modelo $\texttt{TLM-ETS}$ com componentes periódicas de 12 meses e 16 meses, a opção automatizada do pacote $\texttt{ETS()}$, $\texttt{ETS(M,A,A)}$ com seleção automática dos parâmetros $\alpha$, $\beta$ e $\gamma$, bem como $\texttt{ETS(M,A,A)}$ com diferentes valores de $\gamma$ (0.1, 0.5, 0.7). 

A ênfase no estudo dos efeitos desse parâmetro deriva do comportamento observado nos dados. Na parte final dos dados, o componente de tendência aparentemente se torna ausente, enquanto as componentes sazonais identificadas assumem maior relevância.

Os modelos foram criados utilizando as funções `exp_smoothing` e `seasonal_reg`, onde as "engines" são selecionadas através da função set_engine, e a adaptação aos dados é realizada pela função `fit`. Esses modelos estão sendo ajustados com base nos dados de treinamento do primeiro "folder" criado na etapa de criação do plano de validação cruzada.


```{r}
# Modelo automático
ets_auto <- 
 exp_smoothing() %>% 
  set_engine("ets") %>% 
  fit(media ~ mes, training(cv$splits[[1]]))
```

```{r}
#Modelo com multiplas sazonalidades

stl_season <- 
  seasonal_reg(
    seasonal_period_1 = 16,
    seasonal_period_2 = 12
  ) %>% 
  set_engine("stlm_ets") %>% 
  fit(media ~ mes, training(cv$splits[[1]]))
```

```{r}
#Modelo com escolha automática dos parâmetros alpha, beta e gamma

ets_maa <- 
 exp_smoothing(
   seasonal_period  = 16,
   error            = "multiplicative",
   trend            = "additive",
   season           = "additive",
   ) %>% 
  set_engine("ets") %>% 
  fit(media ~ mes, training(cv$splits[[1]]))
```

```{r}
# Modelo com gamma = 0.1
# Atribui peso maior para valores mais distantes
# Maior suavização da curva

ets_b01 <- 
 exp_smoothing(
   seasonal_period  = 16,
   error            = "multiplicative",
   trend            = "additive",
   season           = "additive",
   smooth_level = 0.3,#alpha,
   smooth_trend = 0.01,#beta
   smooth_seasonal =0.1#gamma
   ) %>% 
  set_engine("ets") %>% 
  fit(media ~ mes, training(cv$splits[[1]]))
```

```{r}
# Modelo com gamma = 0.5
# Suavização intermediária

ets_b05 <- 
 exp_smoothing(
   seasonal_period  = 16,
   error            = "multiplicative",
   trend            = "additive",
   season           = "additive",
   smooth_level = 0.3,#alpha,
   smooth_trend = 0.01,#beta
   smooth_seasonal =0.5#gamma
   ) %>% 
  set_engine("ets") %>% 
  fit(media ~ mes, training(cv$splits[[1]]))
```

```{r}
# Modelo com gamma = 0.7
# Atribui peso maior para valores mais próximos
# Menor suavização da curva

ets_b07 <- 
 exp_smoothing(
   seasonal_period  = 16,
   error            = "multiplicative",
   trend            = "additive",
   season           = "additive",
   smooth_level = 0.3,#alpha,
   smooth_trend = 0.01,#beta
   smooth_seasonal =0.7#gamma
   ) %>% 
  set_engine("ets") %>% 
  fit(media ~ mes, training(cv$splits[[1]]))
```

:::

# Comparando os modelos
::: justify
Para comparar o desempenho dos modelos em relação ao conjunto de teste o pacote `modeltime` possui a função `modeltime_table`, projetada para realizar previsões em larga escala utilizando modelos criados com `modeltime`, `parsnip`, `workflows` e outras extensões do ecossistema `tidymodels`. 


```{r}
model_table <- 
  modeltime::modeltime_table(
    ets_auto,
    stl_season,
    ets_maa,
    ets_b01,
    ets_b05,
    ets_b07
    )
```

:::

## Calibrando
::: justify
O processo de calibração estabelece as bases para alcançar precisão e estabelecer as margens de confiança nas previsões, por meio do cálculo de previsões e resíduos com base em dados de teste.


```{r}
calib_table <- 
  model_table %>% 
  modeltime_calibrate(testing(cv$splits[[1]]))
```

:::

## Conjunto de Testes e Acurácia
::: justify
Utilizando os dados que foram calibrados, o próximo passo é realizar previsões com os modelos e compará-las ao conjunto de teste. Isso será realizado utilizando a função `modeltime_forecast`.


```{r}
calib_table %>% 
modeltime::modeltime_forecast(
    new_data = testing(cv$splits[[1]]),
    actual_data = gold_mean
  ) %>% 
  plot_modeltime_forecast(.interactive = TRUE)
```


As metricas de cada modelo são obtidas através da função `modeltime_accuracy`, que simplifica o cálculos das métricas de precisão de regressão de séries temporais a partir de um `workflow` ajustado (treinado) ou modelo ajustado (treinado).


```{r}
calib_table %>% 
  modeltime::modeltime_accuracy() %>% 
  table_modeltime_accuracy(.interactive = FALSE)
```


O modelo ajustado automaticamente (ETS()) claramente não capturou o comportamento dos dados, retornando como previsão o último valor do conjunto de treino (uma abordagem Naïve). Por outro lado, os demais modelos, apesar de apresentarem diferentes níveis de suavidade, parecem ter desempenhado bem na reprodução dos dados de teste. Os modelos, que possuem múltiplas sazonalidades, ETS(M,A,A) com parâmetros alpha, beta e gamma ajustados automaticamente e com o parâmetro gamma igual a 0.5 ( repectivamente 2, 3, 5), mostram formatos e desempenhos semelhantes. Enquanto os modelos ETS(M,A,A) com parâmetro gamma igual a 0.1 e 0.7 (4, 6) demonstraram o melhor desempenho apesar de apresentarem curvas as curvas com maior e menor níveis de suavidade.
:::

## Validação Cruzada
::: justify
Para uma melhor compreenção do desempenho e estabilidade dos modelos que foram ajustado, serão utilizados os folder criados no início deste post, verificando o comportamento dos modelos em diferentes janelas de previsão. 

Para realizar esta etatapa sera utilizada a função `modeltime_fit_resamples`, idealizada para treinar e criar previsões iterativamente a partir de modelos contidos em uma objeto modeltime_table e de conjuntos de reamostragem (CV-folders).


```{r}
resamples_fitted <- model_table %>%
    modeltime_fit_resamples(
        resamples = cv,
        control   = control_resamples(verbose = FALSE)
    )

#resamples_fitted
```


Para avaliar os modelos, será utilizada a função `plot_modeltime_resamples`. Essa função plota a precisão de cada um dos modelos em relação a conjuntos de reamostragem e exibe os comportamentos médios através de linhas verticais. A opção iterativa do gráfico é uma maneira conveniente de avaliar o desempenho dos modelos de forma mais detalhada, permitindo uma avaliação comparativa e individual. 



```{r}
resamples_fitted %>%
    plot_modeltime_resamples(
      .point_size  = 3, 
      .point_alpha = 0.8,
      .interactive = TRUE
    )
```


Em linhas gerais todos os modelos tiveram um comportamento muito parecido em relação aos diferentes folder, apresentando bom desempenho nos quatro primeiros folder e uma piora gradativa nos demais conjuntos. Esse comporatamento indica que os modelos tem uma boa generalização para a parte dos dados que não apresenta trend expressivo e é dominada pela componente sazonal de ~16 meses, já que se observarmos o desempenho dos modelos começa a diminuir quando o conjunto de treinamento passa a ter uma menor quantidade de dados dentro do período dominado pelacomponente periódica e diminui mais ainda quando os conjuntos de teste passa a estar na parte dos dados onde a presença de tendência é mais significativa.

O melhor com o melhor desempenho foi ETS(A,M,M) com os parâmetros alpha, beta e gamma ajustados de modo automático. Entretanto, com excessão do primeiro folder o desempenho dos modelos não difere de modo substâcial, inclusive para o modelo ajustado totalmente de forma automática, que apresenta um comportamento "Naïve". 
:::

## Análise dos Resíduos
::: justify
A análise de resíduos é uma etapa importante na avaliação de modelos de previsão de séries temporais. Ela ajuda a determinar se o modelo escolhido está capturando adequadamente a estrutura da série temporal e se há algum padrão não capturado nos resíduos (os erros do modelo).

A função `plot_modeltime_residuals` oferece um modo prático de avaliar os resíduos dos modelos que foram criados.  


```{r, message=FALSE}
calib_table %>% 
  modeltime_residuals() %>% 
  plot_modeltime_residuals(
     .type = "timeplot",
     .interactive = FALSE
     )
```

```{r, message=FALSE}
calib_table %>% 
  modeltime_residuals() %>% 
  plot_modeltime_residuals(
     .type = "acf",
     .interactive = FALSE
     )
```

:::

# Realizando Previsões Futuras
::: justify
Agora que os modelos já foram ajustados e testados vou criar previsões para além do conjunto de teste. Para isso os modelos serão reajustados, agora no conjunto de dados completo.


```{r}
future_forecast_tbl <- 
  calib_table %>% 
  modeltime_refit(gold_mean) %>% 
  modeltime_forecast(
    h  = "1 year",
    actual_data = gold_mean
  )
```

```{r}
future_forecast_tbl %>% 
  plot_modeltime_forecast(.interactive = TRUE)
```

:::

# Salvando o Modelo
::: justify
Antes de terminar vou salvar o modelo com a melhor performace a fim de furas comparações com outros métodos que serão utilizados no futuro. O modelo escolhido foi...

```{r}
#Período de 16 meses
#Erro multiplicativo
#Trend aditivo
#Sazonalidade aditivo

#saveRDS(es, file = "eng-es-16period-MAA.rds")

```

:::

# Referências
::: justify
[Automatic Time Series Forecasting: the forecast Package for R](https://cran.r-project.org/web/packages/forecast/vignettes/JSS2008.pdf)

[Extending Modeltime (Developer Tools)](https://business-science.github.io/modeltime/articles/extending-modeltime.html)

[es: Exponential Smoothing in SSOE state space model](https://rdrr.io/cran/smooth/man/es.html)

[ets: Exponential smoothing state space model](https://pkg.robjhyndman.com/forecast/reference/ets.html)

[Forecasting: Principles and Practice (3rd ed)-Chapter 8 Exponential smoothing](https://otexts.com/fpp3/expsmooth.html)

[Forecasting using stl objects](https://pkg.robjhyndman.com/forecast/reference/forecast.stl.html)

[General Interface for Exponential Smoothing State Space Models](https://business-science.github.io/modeltime/reference/exp_smoothing.html)

[General Interface for Multiple Seasonality Regression Models (TBATS, STLM)](https://business-science.github.io/modeltime/reference/seasonal_reg.html)
:::

